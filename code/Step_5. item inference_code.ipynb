{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curl -fsSL https://ollama.com/install.sh | sh && ollama serve > ollama.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myconfig():\n",
    "    data_path = r\"/home/work/lib_data/KISTI/0709_final_gt_data.xlsx\"\n",
    "    prompt_path = r\"/home/work/lib_data/KISTI/0709_최종 prompt 후보.xlsx\"\n",
    "mcfg = myconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "summary_data = pd.read_excel(mcfg.data_path)\n",
    "title = list(summary_data[\"title\"])\n",
    "summary = list(summary_data[\"summary\"])\n",
    "\n",
    "prompt_cand = list(pd.read_excel(mcfg.prompt_path)[\"candidates\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [{'name': 'llama3:70b-instruct',\n",
       "   'model': 'llama3:70b-instruct',\n",
       "   'modified_at': '2024-07-11T04:38:12.415784597Z',\n",
       "   'size': 39969745349,\n",
       "   'digest': '786f3184aec0e907952488b865362bdaa38180739a9881a8190d85bad8cab893',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '70.6B',\n",
       "    'quantization_level': 'Q4_0'}}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "ollama_model = \"llama3:70b-instruct\"\n",
    "# ollama_model = \"llama3:8b\"\n",
    "# ollama_model = 'llama3:latest'\n",
    "# ollama.pull(ollama_model)\n",
    "ollama.list()\n",
    "# ollama.delete(ollama_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm delighted to introduce myself! I'm a Business Consultant and Strategist, which means I help entrepreneurs, startups, and established companies alike to improve their operations, increase efficiency, and drive growth.\n",
      "\n",
      "My expertise spans across various aspects of business, including:\n",
      "\n",
      "1. **Business Planning**: I assist clients in developing comprehensive business plans, outlining goals, strategies, and tactics to achieve success.\n",
      "2. **Operational Efficiency**: I analyze and optimize business processes to reduce costs, enhance productivity, and improve overall performance.\n",
      "3. **Market Research and Analysis**: I provide insights on market trends, competitors, and customer needs to inform strategic decisions.\n",
      "4. **Financial Management**: I offer guidance on financial planning, budgeting, and forecasting to ensure sustainable growth and profitability.\n",
      "5. **Leadership and Team Development**: I coach business leaders and teams to improve communication, collaboration, and leadership skills.\n",
      "\n",
      "My ultimate goal is to empower businesses to reach their full potential, overcome challenges, and achieve long-term success.\n",
      "\n",
      "How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(\n",
    "    model=ollama_model,\n",
    "    messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful expert of business. Follow the instruction.\"},\n",
    "    {'role': 'user', 'content': \"what is your job?\"}],\n",
    "    )\n",
    "print((response['message']['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for instruction in prompt_cand:\n",
    "    result = []\n",
    "    \n",
    "    for i in range(len(title)):\n",
    "        \n",
    "        prompt = f\"\"\"{instruction}\n",
    "\n",
    "input: {title[i]}\n",
    "{summary[i]}\n",
    "\n",
    "output: \"\"\"\n",
    "        \n",
    "        response = ollama.chat(\n",
    "            model=ollama_model,\n",
    "            messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful expert of business. Follow the instruction.\"},\n",
    "            {'role': 'user', 'content': prompt}],\n",
    "            )\n",
    "        result.append(response['message']['content'])\n",
    "        print((response['message']['content']))\n",
    "        print(\"------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    final_result.append(result)\n",
    "    print(result)\n",
    "    print(\"------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"------------------------------------------------------------------------------------------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
